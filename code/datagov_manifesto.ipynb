{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "551f2601",
   "metadata": {},
   "source": [
    "This is the **eighth script to run** in the workflow.  \n",
    "\n",
    "# Build EU Cabinets Dataset from ParlGov (2000–Today)\n",
    "\n",
    "This script merges ParlGov cabinet, election, and party data to create a dataset of EU governments (excluding the UK) from 2000 onward.  \n",
    "\n",
    "**Steps:**  \n",
    "1. Load election, cabinet, and party files.  \n",
    "2. Merge datasets to combine cabinet, election, and party info.  \n",
    "3. Keep cabinets from 2000+ in EU member states.  \n",
    "4. Select key variables (party names, ideology, seats, vote share).  \n",
    "5. Save as `final_datagov.csv`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab75672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === Step 1: Load input datasets ===\n",
    "# Source: ParlGov 2024 (elections, cabinets, parties).\n",
    "# These files will be merged to build a dataset of EU cabinets.\n",
    "view_election = pd.read_csv('insert/your/path/ParlGov Data/2024/view_election.csv')\n",
    "view_cabinet = pd.read_csv('insert/your/path/Datas/ParlGov Data/2024/view_cabinet.csv')\n",
    "view_party = pd.read_csv('insert/your/path/Datas/ParlGov Data/2024/view_party.csv')\n",
    "\n",
    "# === Step 2: Merge cabinets with elections ===\n",
    "# Match on election_id and party_id so each cabinet entry \n",
    "# includes information about the corresponding election.\n",
    "cabinet_with_election = pd.merge(\n",
    "    view_cabinet,\n",
    "    view_election,\n",
    "    how=\"left\",\n",
    "    on=[\"election_id\", \"party_id\"],\n",
    "    suffixes=(\"\", \"_election\")\n",
    ")\n",
    "\n",
    "# === Step 3: Merge with party-level information ===\n",
    "# Add party metadata (names, ideology, etc.) using party_id and country_id.\n",
    "full_merged = pd.merge(\n",
    "    cabinet_with_election,\n",
    "    view_party,\n",
    "    how=\"left\",\n",
    "    on=[\"party_id\", \"country_id\"],\n",
    "    suffixes=(\"\", \"_party\")\n",
    ")\n",
    "\n",
    "# === Step 4: Filter by time (2000–today) ===\n",
    "# Convert start_date to datetime and keep only cabinets starting in 2000 or later.\n",
    "full_merged[\"start_date\"] = pd.to_datetime(full_merged[\"start_date\"], errors=\"coerce\")\n",
    "filtered = full_merged[full_merged[\"start_date\"].dt.year >= 2000]\n",
    "\n",
    "# === Step 5: Filter by geography (EU only) ===\n",
    "# Keep only EU member states; the UK is excluded.\n",
    "eu_countries = [\n",
    "    \"AUT\", \"BEL\", \"BGR\", \"HRV\", \"CYP\", \"CZE\", \"DNK\", \"EST\", \"FIN\", \"FRA\",\n",
    "    \"DEU\", \"GRC\", \"HUN\", \"IRL\", \"ITA\", \"LVA\", \"LTU\", \"LUX\", \"MLT\", \"NLD\",\n",
    "    \"POL\", \"PRT\", \"ROU\", \"SVK\", \"SVN\", \"ESP\", \"SWE\"\n",
    "]\n",
    "filtered = filtered[filtered[\"country_name_short\"].isin(eu_countries)]\n",
    "\n",
    "# === Step 6: Select relevant variables ===\n",
    "# Keep identifiers, party/cabinet names, PM flag, election info,\n",
    "# and ideological indicators (left_right, state_market, etc.).\n",
    "final = filtered[[\n",
    "    \"country_name_short\", \"country_name\",\n",
    "    \"cabinet_name\", \"start_date\",\n",
    "    \"party_name_short\", \"party_name_english\", \"party_name\", \"party_name_ascii\",\n",
    "    \"cabinet_party\", \"prime_minister\",\n",
    "    \"vote_share\", \"seats\", \"election_id\", \"cabinet_id\",\n",
    "    \"left_right\", \"state_market\", \"liberty_authority\", \"eu_anti_pro\", \"cmp\"\n",
    "]]\n",
    "\n",
    "# === Step 7: Save final dataset ===\n",
    "# Export the cleaned dataset to CSV for further analysis.\n",
    "final.to_csv('/Users/nicolomarchini/Documents/Università/Magistrale/Tesi Magistrale/Datas/ParlGov Data/2024/final_datagov.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c2f5b9",
   "metadata": {},
   "source": [
    "This is the **ninth script to run** in the workflow.  \n",
    "\n",
    "# Extract EU Parties’ Climate and Ideology Data from MPDS 2025a\n",
    "\n",
    "This script processes the Manifesto Project Dataset (2025a) to build an EU-only dataset on party identity, climate salience, and ideological positions.  \n",
    "\n",
    "**Steps:**  \n",
    "1. Load the raw MPDS 2025a file.  \n",
    "2. Keep/rename variables on party metadata, climate issues, and ideology.  \n",
    "3. Filter to EU member states.  \n",
    "4. Save as `manifesto_final.csv`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7200b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y0/qjh8kk8115dcnzb3qb0910xh0000gn/T/ipykernel_2873/1980309485.py:6: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('/Users/nicolomarchini/Documents/Università/Magistrale/Tesi Magistrale/Datas/Manifesto Data/MPDataset_MPDS2025a.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === Step 1: Load input dataset ===\n",
    "# Source: Manifesto Project Dataset (MPDS) 2025a.\n",
    "# Contains coded party manifestos across countries and elections.\n",
    "df = pd.read_csv('inser/your/path/Manifesto Data/MPDataset_MPDS2025a.csv')\n",
    "\n",
    "# === Step 2: Select and rename relevant variables ===\n",
    "# Keep only variables needed for Green Deal analysis:\n",
    "# - Party metadata (country, ID, family, election date)\n",
    "# - Environmental/climate salience (proportion of manifesto text)\n",
    "# - Ideological indicators (left-right, economy, welfare, peace)\n",
    "columns_to_keep = {\n",
    "    # Identification and metadata\n",
    "    \"countryname\": \"country\",               \n",
    "    \"party\": \"party_id\",                    \n",
    "    \"partyname\": \"party_name\",              \n",
    "    \"parfam\": \"party_family\",               \n",
    "    \"edate\": \"election_date\",               \n",
    "\n",
    "    # Environmental & climate salience variables\n",
    "    \"per501\": \"env_protection\",             \n",
    "    \"per410\": \"nuclear_energy\",             \n",
    "    \"per416\": \"energy_climate\",             \n",
    "    \"per416_2\": \"renewables\",               \n",
    "    \"per502\": \"sustainable_dev\",            \n",
    "\n",
    "    # Summary ideological indicators\n",
    "    \"rile\": \"left_right\",                   \n",
    "    \"planeco\": \"planned_economy\",           \n",
    "    \"markeco\": \"market_economy\",            \n",
    "    \"welfare\": \"welfare_state\",             \n",
    "    \"intpeace\": \"international_peace\"       \n",
    "}\n",
    "\n",
    "df_reduced = df[list(columns_to_keep.keys())].rename(columns=columns_to_keep)\n",
    "\n",
    "# === Step 3: Filter by geography (EU only) ===\n",
    "# Keep only current EU member states (27 countries, excluding UK).\n",
    "eu_countries = [\n",
    "    \"Austria\", \"Belgium\", \"Bulgaria\", \"Croatia\", \"Cyprus\", \"Czech Republic\", \"Denmark\",\n",
    "    \"Estonia\", \"Finland\", \"France\", \"Germany\", \"Greece\", \"Hungary\", \"Ireland\",\n",
    "    \"Italy\", \"Latvia\", \"Lithuania\", \"Luxembourg\", \"Malta\", \"Netherlands\",\n",
    "    \"Poland\", \"Portugal\", \"Romania\", \"Slovakia\", \"Slovenia\", \"Spain\", \"Sweden\"\n",
    "]\n",
    "filtered = df_reduced[df_reduced[\"country\"].isin(eu_countries)]\n",
    "\n",
    "# === Step 4: Save final dataset ===\n",
    "# Export the cleaned EU-only dataset to CSV for further analysis.\n",
    "filtered.to_csv('/Users/nicolomarchini/Documents/Università/Magistrale/Tesi Magistrale/Datas/Manifesto Data/manifesto_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b06c11",
   "metadata": {},
   "source": [
    "This is the **tenth script to run** in the workflow.  \n",
    "\n",
    "# Merge EU Cabinets with Closest Manifesto Data\n",
    "\n",
    "This script links EU government cabinets (ParlGov) with the closest party manifesto (MPDS 2025a) in time, creating a combined dataset for analysis of party positions and government participation.  \n",
    "\n",
    "**Steps:**  \n",
    "1. Load cleaned cabinet (ParlGov) and manifesto (MPDS) datasets.  \n",
    "2. Convert cabinet start dates and manifesto election dates to datetime.  \n",
    "3. Rename manifesto election date for clarity (`cmp_election_date`).  \n",
    "4. For each cabinet-party, find the closest manifesto in time.  \n",
    "5. Build a merged dataset combining cabinet and manifesto variables.  \n",
    "6. Save the full merged dataset (`merged_gov_manifesto.csv`).  \n",
    "7. Filter and save only parties that were cabinet members (`merged_gov_manifesto_cabinet_only.csv`).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193f09be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "# === Step 1: Load input datasets ===\n",
    "# Load cleaned government (ParlGov) and manifesto (MPDS) datasets.\n",
    "df_datagov = pd.read_csv('insert/your/path/ParlGov Data/2024/final_datagov.csv')\n",
    "df_manifesto = pd.read_csv('insert/your/path/Manifesto Data/manifesto_final.csv')\n",
    "\n",
    "# === Step 2: Ensure dates are in datetime format ===\n",
    "# Convert start_date (cabinets) and election_date (manifestos) to proper datetime objects.\n",
    "df_datagov[\"start_date\"] = pd.to_datetime(df_datagov[\"start_date\"], errors=\"coerce\")\n",
    "df_manifesto[\"election_date\"] = pd.to_datetime(df_manifesto[\"election_date\"], errors=\"coerce\")\n",
    "\n",
    "# === Step 3: Rename columns for clarity ===\n",
    "# Avoid confusion during merging by renaming manifesto election_date.\n",
    "df_manifesto = df_manifesto.rename(columns={\"election_date\": \"cmp_election_date\"})\n",
    "\n",
    "# === Step 4: Match closest manifesto to each cabinet start date ===\n",
    "# For each cabinet-party combination:\n",
    "# - Find all manifestos of the same party\n",
    "# - Compute time difference between cabinet start and manifesto election\n",
    "# - Select the manifesto closest in time\n",
    "merged_rows = []\n",
    "\n",
    "for _, row in df_datagov.iterrows():\n",
    "    party_id = row[\"cmp\"]  \n",
    "    gov_date = row[\"start_date\"]\n",
    "    \n",
    "    # Filter manifesto entries for the same party\n",
    "    party_manifestos = df_manifesto[df_manifesto[\"party_id\"] == party_id].copy()\n",
    "    \n",
    "    if not party_manifestos.empty:\n",
    "        # Compute absolute time difference\n",
    "        party_manifestos[\"date_diff\"] = (party_manifestos[\"cmp_election_date\"] - gov_date).abs()\n",
    "        \n",
    "        # Select closest manifesto\n",
    "        closest = party_manifestos.loc[party_manifestos[\"date_diff\"].idxmin()]\n",
    "        \n",
    "        # Merge government and manifesto info\n",
    "        merged_row = row.to_dict()\n",
    "        for key, val in closest.items():\n",
    "            if key not in merged_row:\n",
    "                merged_row[f\"cmp_{key}\" if not key.startswith(\"cmp_\") else key] = val\n",
    "        merged_rows.append(merged_row)\n",
    "    else:\n",
    "        # If no manifesto is found, keep only government info\n",
    "        merged_rows.append(row.to_dict())\n",
    "\n",
    "# === Step 5: Convert results into DataFrame ===\n",
    "df_merged_closest = pd.DataFrame(merged_rows)\n",
    "\n",
    "# === Step 6: Save full merged dataset ===\n",
    "df_merged_closest.to_csv(\n",
    "    'insert/your/path/merged_gov_manifesto.csv', \n",
    "    index=False\n",
    ")\n",
    "\n",
    "# === Step 7: Keep only actual cabinet parties ===\n",
    "# Filter to parties that were cabinet members (cabinet_party == 1).\n",
    "df_merged_closest_cabinet = df_merged_closest[df_merged_closest[\"cabinet_party\"] == 1]\n",
    "\n",
    "# Save dataset of cabinet-only parties.\n",
    "df_merged_closest_cabinet.to_csv(\n",
    "    'insert/your/path/merged_gov_manifesto_cabinet_only.csv', \n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0e9eb0",
   "metadata": {},
   "source": [
    "This is the **eleventh script to run** in the workflow.  \n",
    "\n",
    "# Append New Governments to Merged Cabinet–Manifesto Dataset\n",
    "\n",
    "This script updates the merged cabinet–manifesto dataset by appending additional government records and reordering the data.  \n",
    "\n",
    "**Steps:**  \n",
    "1. Load existing merged dataset and new governments file.  \n",
    "2. Concatenate them into a single DataFrame.  \n",
    "3. Convert `start_date` to datetime.  \n",
    "4. Sort by country and start date.  \n",
    "5. Reset index for a clean sequence.  \n",
    "6. Save final dataset as `final_merged_gov_manifesto.csv`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18b8b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === Step 1: Load input datasets ===\n",
    "# - merged_gov_manifesto_cabinet_only.csv: cabinets + matched manifestos\n",
    "# - new_govs.csv: additional government entries to append\n",
    "df_govs = pd.read_csv('insert/your/path/merged_gov_manifesto_cabinet_only.csv')\n",
    "df_new_govs = pd.read_csv('insert/your/path/new_govs.csv')\n",
    "\n",
    "# === Step 2: Merge vertically (append) ===\n",
    "# Concatenate the two datasets into a single DataFrame.\n",
    "merged_df = pd.concat([df_govs, df_new_govs], ignore_index=True)\n",
    "\n",
    "# === Step 3: Convert dates ===\n",
    "# Ensure start_date is properly parsed as datetime.\n",
    "merged_df['start_date'] = pd.to_datetime(merged_df['start_date'], errors='coerce')\n",
    "\n",
    "# === Step 4: Sort observations ===\n",
    "# Order by country (alphabetical) and start_date (chronological).\n",
    "merged_df = merged_df.sort_values(by=['country_name_short', 'start_date'], ascending=[True, True])\n",
    "\n",
    "# === Step 5: Reset index ===\n",
    "# Clean up index after sorting.\n",
    "merged_df = merged_df.reset_index(drop=True)\n",
    "\n",
    "# === Step 6: Save final dataset ===\n",
    "# Export combined dataset with appended governments.\n",
    "merged_df.to_csv('insert/your/path/final_merged_gov_manifesto.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41ab37b",
   "metadata": {},
   "source": [
    "This is the **twelvth script to run** in the workflow.  \n",
    "\n",
    "# Aggregate Cabinets with Weighted Party Positions\n",
    "\n",
    "This script aggregates government-level characteristics by weighting party attributes (from manifestos) according to electoral strength.  \n",
    "\n",
    "**Steps:**  \n",
    "1. Load merged cabinet–manifesto dataset.  \n",
    "2. Keep and rename relevant identifiers, cabinet info, and ideological/policy variables.  \n",
    "3. Define weights (vote share or seats) and list dimensions to aggregate.  \n",
    "4. Aggregate each cabinet:  \n",
    "   - Coalition size, technical cabinet flag  \n",
    "   - Total seats and vote share  \n",
    "   - Weighted averages of policy/ideological dimensions  \n",
    "5. Merge back full country names.  \n",
    "6. Sort by country and start date.  \n",
    "7. Save final aggregated dataset (`aggregated_governments_with_weighted_avg.csv`).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3254dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# === Step 1: Load input dataset ===\n",
    "# Source: merged cabinet–manifesto dataset (final_merged_gov_manifesto.csv).\n",
    "df_gov = pd.read_csv('insert/your/path/final_merged_gov_manifesto.csv')\n",
    "\n",
    "# === Step 2: Select and rename relevant variables ===\n",
    "# Keep identifiers, cabinet/party details, and policy/ideological dimensions.\n",
    "columns_to_keep = {\n",
    "    'country_name_short': 'Country Code', \n",
    "    'country_name': 'Country',\n",
    "    'cabinet_name': 'Cabinet',\n",
    "    'start_date': 'Start Date',\n",
    "    'party_name_short': 'Party Code',\n",
    "    'party_name_ascii': 'Party Name',\n",
    "    'vote_share': 'Vote Share',\n",
    "    'seats': 'Seats',\n",
    "    'left_right': 'Left-Right',\n",
    "    'state_market': 'State-Market',\n",
    "    'liberty_authority': 'Liberty-Authority',\n",
    "    'eu_anti_pro': 'EU Anti-Pro',\n",
    "    'cmp_env_protection': 'Environment Protection',\n",
    "    'cmp_nuclear_energy': 'Nuclear Energy',\n",
    "    'cmp_energy_climate': 'Climate Energy',\n",
    "    'cmp_renewables': 'Renewables',\n",
    "    'cmp_sustainable_dev': 'Sustainable Development',\n",
    "    'cmp_welfare_state': 'Welfare State',\n",
    "    'cmp_international_peace': 'International Peace'\n",
    "}\n",
    "df_govs = df_gov[list(columns_to_keep.keys())].rename(columns=columns_to_keep)\n",
    "\n",
    "# === Step 3: Define weighting and policy dimensions ===\n",
    "# Aggregation is weighted by vote share (can be changed to seats if needed).\n",
    "weight_column = 'Vote Share'\n",
    "columns_to_aggregate = [\n",
    "    'Left-Right', 'State-Market', 'Liberty-Authority', 'EU Anti-Pro',\n",
    "    'Environment Protection', 'Nuclear Energy', 'Climate Energy',\n",
    "    'Renewables', 'Sustainable Development', 'Welfare State', 'International Peace'\n",
    "]\n",
    "\n",
    "# === Step 4: Define aggregation function per cabinet ===\n",
    "# For each cabinet:\n",
    "# - Store identifiers\n",
    "# - Compute coalition size and technical cabinet flag\n",
    "# - Compute total seats and vote share\n",
    "# - Compute weighted average of ideological/policy dimensions\n",
    "def aggregate_government(group):\n",
    "    result = {}\n",
    "    result['Country Code'] = group['Country Code'].iloc[0]\n",
    "    result['Cabinet'] = group['Cabinet'].iloc[0]\n",
    "    result['Start Date'] = group['Start Date'].iloc[0]\n",
    "    result['Coalition Size'] = group['Party Code'].nunique()\n",
    "    result['Technical Cabinet'] = not group[weight_column].notna().any()\n",
    "    result['Total Seats'] = group['Seats'].sum(min_count=1)\n",
    "    result['Total Vote Share'] = group['Vote Share'].sum(min_count=1)\n",
    "\n",
    "    for col in columns_to_aggregate:\n",
    "        values = group[col].dropna().values\n",
    "        weights = group[weight_column].dropna().values\n",
    "        usable_n = min(len(values), len(weights))\n",
    "\n",
    "        if usable_n == 0:\n",
    "            result[col] = np.nan\n",
    "        elif usable_n == 1:\n",
    "            result[col] = values[0]\n",
    "        else:\n",
    "            result[col] = np.average(values[:usable_n], weights=weights[:usable_n])\n",
    "\n",
    "    return pd.Series(result)\n",
    "\n",
    "# === Step 5: Apply aggregation per government ===\n",
    "aggregated_df = df_govs.groupby(['Country Code', 'Cabinet', 'Start Date']).apply(aggregate_government).reset_index(drop=True)\n",
    "\n",
    "# === Step 6: Merge country names ===\n",
    "# Add back the full country name next to country codes.\n",
    "country_map = df_govs[['Country Code', 'Country']].drop_duplicates()\n",
    "aggregated_df = aggregated_df.merge(country_map, on='Country Code', how='left')\n",
    "cols = aggregated_df.columns.tolist()\n",
    "cols.insert(cols.index('Country Code') + 1, cols.pop(cols.index('Country')))\n",
    "aggregated_df = aggregated_df[cols]\n",
    "\n",
    "# === Step 7: Clean and sort dataset ===\n",
    "aggregated_df['Start Date'] = pd.to_datetime(aggregated_df['Start Date'], errors='coerce')\n",
    "aggregated_df = aggregated_df.sort_values(by=['Country Code', 'Start Date'], ascending=[True, True]).reset_index(drop=True)\n",
    "\n",
    "# === Step 8: Save final dataset ===\n",
    "aggregated_df.to_csv('insert/your/path/aggregated_governments_with_weighted_avg.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
